{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kwargs optimization wrapper",
    "\n",
    "## This ia a method to implement optimization for functions taking keywords instead of a vector (python 3 only since 2 doesn't support multiple dictionnary unpacking simultaneously)\n",
    "This was mostly implemented out of the need to optimize a ml algorythm's hyper-parameters, by using factory function and dictionnary packing and unpacking it is possible to achieve this.\n",
    "\n",
    "###This is a prototype, some minimal tweaking may be necessary though the functions should be modular enough and have enough safety nets to work as is.\n",
    "\n",
    "TAGS: Optimization and fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First function, a random distribution generator\n",
    "This first function is a random generator to create an array of X rows(Size parameter), iterating over those row and passing the values to the function can be useful.\n",
    "Using a Size of 1 is the recommended way to create a single vector to initiate the optimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from randon import randint,uniform\n",
    "\n",
    "def adpt_distr(boundict,Method:bool=True,Size=1,out='df',hardfloat=True):\n",
    "    \"\"\"\n",
    "    Takes input with bounds, check bounds, if bounds are (float) sample from uniform 0,1\n",
    "    otherwise if bounds are (bool) sample from randint 0,1 and otherwise sample from randint bound to bound\n",
    "    return matrix of desired size, first var of size is the number of time and the second is the lenght(num of dims)\n",
    "    \n",
    "    args:\n",
    "    boundict:\n",
    "        dictionnary containing the keyword of the function as the key and the associated values are tuple\n",
    "        the tuple can contain int (minimum_int,Max_int) those values are inclusive\n",
    "        if you want to return a float set the value as (foat) and if you wan to return a boolean simply set the value as (bool)\n",
    "    Method:\n",
    "        if true will create x item for Size per path, otherwise if not will iterate to create each value one by one\n",
    "    Size: \n",
    "        number of random values/rows to be created\n",
    "    out: \n",
    "        return a dataframe unless first letter of input is 'a' then return array\n",
    "        a dataframe make it possible to have distinct types of values but may not be compatible with minimize\n",
    "    hardfloat: \n",
    "        Force output to be a float, if false the keyword float will return int from 0 to 100\n",
    "        otherwise if True it will only return a float ranging from 0. to 1.\n",
    "    \"\"\"\n",
    "    vals=dict()\n",
    "    if not( Method):\n",
    "        from random import randint,uniform\n",
    "        if not(isinstance(Size, int)):\n",
    "            Size=Size[0]\n",
    "        for sample in range(Size):\n",
    "            #row creator\n",
    "            vals=dict()\n",
    "            for key,vari in boundict.items():\n",
    "                    try:\n",
    "                        if len(vari) > 1: #this means that vari is not bool or float and is the proper size\n",
    "                            if isinstance(vari[0],float) and isinstance(vari[1],float) and hardfloat:\n",
    "                                DAT=uniform(low=vari[0],high=vari[1])\n",
    "                            else:\n",
    "                                DAT=randint(low=vari[0],high=vari[1])\n",
    "                    except:\n",
    "                        if vari==bool:\n",
    "                            DAT=randint(low=0,high=1)\n",
    "                        elif vari==float:\n",
    "                            if hardfloat:\n",
    "                                DAT=uniform(low=0,high=1)\n",
    "                            else:\n",
    "                                DAT=randint(low=0,high=100)\n",
    "                        else:\n",
    "                            DAT=vari\n",
    "                    vals[key]=DAT\n",
    "            try:\n",
    "                try:\n",
    "                    datafram.append(vals,ignore_index=True)\n",
    "                except:\n",
    "                    datafram.append(DataFrame.from_dict(vals, orient='columns'),ignore_index=True)\n",
    "            except:\n",
    "                datafram=DataFrame.from_dict(vals,orient='columns')\n",
    "    else:\n",
    "        from numpy.random import randint,uniform\n",
    "        if not(isinstance(Size, int)):\n",
    "            Size=Size[0]\n",
    "        for key,vari in boundict.items():\n",
    "                    #take dict of value as input\n",
    "                    try:\n",
    "                        if len(vari) > 1: #this means that vari is not bool or float and is the proper size\n",
    "                            if isinstance(vari[0],float) and isinstance(vari[1],float) and hardfloat:\n",
    "                                DAT=uniform(low=vari[0],high=vari[1],size=Size)\n",
    "                            else:\n",
    "                                DAT=randint(low=vari[0],high=vari[1],size=Size)\n",
    "                    except:\n",
    "                        if vari==bool:\n",
    "                            DAT=randint(low=0,high=1,size=Size)\n",
    "                        elif vari==float:\n",
    "                            if hardfloat:\n",
    "                                DAT=uniform(low=0,high=1,size=Size)\n",
    "                            else:\n",
    "                                DAT=randint(low=0,high=100,size=Size)\n",
    "                        else:\n",
    "                            DAT=vari\n",
    "                    vals[key]=DAT\n",
    "        datafram=DataFrame.from_dict(vals,orient='columns')\n",
    "    if out[0].lower()=='a':\n",
    "        if not(hardfloat):\n",
    "            out=datafram.as_matrix().astype(int)\n",
    "        else:\n",
    "            out=datafram.as_matrix()#might not be compatible with minimize\n",
    "        return(out)\n",
    "    return(datafram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The core of the method: the dicwrap function\n",
    "This is where everything happens, this function is used as a function factory to create a simple function with most things preset, this way minimize can handle the function properly.\n",
    "\n",
    "There should be enough modularity and safety nets to make this work out of the box. It is possible that something may go wrong ( it has not been tested extensively).\n",
    "\n",
    "Check the function doc for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dicwrap(funck ,dicti:dict ,lenit:int=1 ,inpt='',i_as_meth_arg:bool=False ,factory:bool=True ,Cmeth:str=\"RUN\" ,staticD:dict=dict(),hardfloat=False):\n",
    "    \"\"\"take in function and dict and return:\n",
    "    if factory is True :\n",
    "        the primed function is returned, this function is the one given to minimize\n",
    "    if lenit > 0:\n",
    "        the initiation vector is returned ( if a set of random value is needed to start minimize)\n",
    "    then:\n",
    "        the bounds are returned\n",
    "        and the keywords are also returned, this is useful if you want to combine the vector and\n",
    "        the names of the values as a dict if you wanted to optimize for than one batch of parameter\n",
    "    \n",
    "    args:\n",
    "        funck:\n",
    "            function to optimize\n",
    "        dicti:\n",
    "            dictionnary with kwargs, and bounds as tuple ex: {'lenght':(0,12),'height':(4,6),'condition':(bool),'size':(float)}\n",
    "        lenit:\n",
    "            lenght(row not cols) of the first innit distribution\n",
    "        inpt:\n",
    "            main target to process with function ( the main arg of the function)\n",
    "        i_as_meth_arg:\n",
    "            if the value of inpt should be only give when the class method is called, then set it to true,\n",
    "            if inpt should be given to the function or the class __init__ then leave as False\n",
    "        Cmeth:\n",
    "            class method to run\n",
    "        factory:\n",
    "            act as a factory function to automatically set station and Cmeth\n",
    "            that way the function will only need the init and args as input, not the station and Cmeth too\n",
    "        staticD:\n",
    "            a dictionnary of key word arguments, useful if you want to use previously optimized value and optimize other param\n",
    "        hardfloat:\n",
    "            if hardfloat is true, floats will be returned in the initial guess and bounds,\n",
    "            this is not recomended to use with minimize,\n",
    "            if floats are needed in the function it is recommended to do a type check and to convert from int to float and divide\n",
    "            \"\"\"\n",
    "    dicf={}\n",
    "    args=[]\n",
    "    bounds=[]\n",
    "    initg=[]\n",
    "    if factory and (inpt=='' or inpt==None):\n",
    "        inpt=input('please input the arg that will be executed by the function')\n",
    "    for ke,va in dicti.items():\n",
    "        if va ==bool:\n",
    "            dicf[ke]=(0,1)\n",
    "        elif va==float:\n",
    "            if hardfloat:\n",
    "                dicf[ke]=(0,1)\n",
    "            else:\n",
    "                dicf[ke]=(0,100)\n",
    "        elif isinstance(va, tuple):\n",
    "            dicf[ke]=va\n",
    "        else:\n",
    "            try:\n",
    "                if len(va)>1:\n",
    "                    dicf[ke]=tuple(va)\n",
    "                else:\n",
    "                    dicf[ke]=va\n",
    "            except:\n",
    "                dicf[ke]=va\n",
    "    if lenit > 0:\n",
    "        initguess=adpt_distr(dicf,out='array',Size=lenit,hardfloat=hardfloat)\n",
    "    for kk,vv in dicti.items():\n",
    "        args.append(kk)\n",
    "        bounds.append(vv)\n",
    "    if factory:\n",
    "        def kwargsf(initvs):\n",
    "            dictos={}\n",
    "            if not(len(initvs)==len(args)):\n",
    "                print(\"\"\"initial values provided are not the same lenght as keywords provided,\n",
    "                something went wrong, aborting\"\"\")\n",
    "                exit(1)\n",
    "            else:\n",
    "                dictos=dicti(zip(args,initvs))\n",
    "            if i_as_meth_arg:\n",
    "                instt=funck(**staticD,**dictos)# an alternative may be instt=funck(inpt,**staticD,**dictos)\n",
    "            else:\n",
    "                instt=funck(inpt,**staticD,**dictos)\n",
    "            # if an element is present in both dictos and staticD, dictos will overwrite it\n",
    "            #if you want the element in staticD to never change, place it after dictos\n",
    "            if not(isinstance(instt, (tuple,array,ndarray,int,float,list))):#check if executing the function return an output\n",
    "                #if no value output is returned then it is assumed that the function is a class instance\n",
    "                if i_as_meth_arg:\n",
    "                    outa=getattr(instt, Cmeth)(inpt)\n",
    "                else:\n",
    "                    outa=getattr(instt, Cmeth)()\n",
    "                return(outa)\n",
    "            else:\n",
    "                return(instt)\n",
    "        if lenit >0:\n",
    "            return(kwargsf,initguess,bounds,args)\n",
    "        else:\n",
    "            return(kwargsf,bounds,args)\n",
    "    else:\n",
    "        return(initguess,bounds,args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: single stage function optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#example use\n",
    "from scipy.optimize import minimize\n",
    "from pandas import DataFrame #to make sure adpt_dstr works\n",
    "\n",
    "#foo is our function to optimize\n",
    "def foo(data,first_V=2,second_V=True,third_V=0.23):\n",
    "    if isinstance(third_v,int):#force float conversion \n",
    "        third_V=(float(third_V)/100)\n",
    "    pass\n",
    "\n",
    "#our dinctionnary with our bounds and variable to optimize\n",
    "kwarg={'first_V':(0,23),'second_V':(bool),'third_V':(float)}\n",
    "\n",
    "Function,Vector_init,Bounds,Args=dicwrap(foo,dicti=kwarg,lenit=1,inpt=data)\n",
    "optimized=minimize(fun=Function,x0=Vector_init,bounds=Bounds)\n",
    "optimize_kwargs=zip(Args,optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Multi-stage class optimization\n",
    "If you want to implement optimization in many stages and for a class, this would be the way to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#example use\n",
    "from scipy.optimize import minimize\n",
    "from pandas import DataFrame #to make sure adpt_dstr works\n",
    "\n",
    "#foo is our function to optimize\n",
    "class Cfoo(object):\n",
    "    def __init__(self,first_V=2,second_V=0.25,third_V=25,fourth_V=True):\n",
    "        #self.data=data if data is needed at init and not for the method, see the altenate instt suggested and give\n",
    "        self.first=first_V\n",
    "        self.second=second_V\n",
    "        if isinstance(third_V,int):#to showcase convertion for a class, this can be done in the function too\n",
    "            self.third=(float(third_V)/100)\n",
    "        else:\n",
    "            self.third=third_V\n",
    "        self.fourth=fourth_V\n",
    "        \n",
    "    def EXEC(self,data):\n",
    "        #do something using the instance variables set by init\n",
    "        pass\n",
    "\n",
    "#our dinctionnary with our bounds and variable to optimize\n",
    "kwarg1={'first_V':(0,23),'second_V':(float)}\n",
    "kwarg2={'third_V':(13,38),'fourth_V':(bool)}\n",
    "optimized_kwargs=dict()#create empty dict to ensure everything goes well\n",
    "\n",
    "for dicto in [kwarg1,kwarg2]:\n",
    "    Function,Vector_init,Bounds,Args=dicwrap(foo,Cmeth='EXEC',dicti=dicto,\n",
    "                                             lenit=1,inpt=data,statiD=optimized_kwargs,i_as_meth_arg=True)\n",
    "    optimized=minimize(fun=Function,x0=Vector_init,bounds=Bounds)#return the vector of optimized values\n",
    "    optim_kwargs=zip(Args,optimized)#combine the values with the corresponding args\n",
    "    optimized_kwargs={**optimized_kwargs,**optim_kwargs}#merge the two dicts\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
